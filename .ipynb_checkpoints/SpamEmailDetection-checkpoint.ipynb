{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6fe5515a-57e6-4115-a645-48edb0498c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in d:\\anaconda\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: pandas in d:\\anaconda\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in d:\\anaconda\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\anaconda\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: nltk in d:\\anaconda\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in d:\\anaconda\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in d:\\anaconda\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\anaconda\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install pandas\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "47a609b1-6aba-41c2-815c-2521840fcd9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Subject: re : receipts from visit  jim ,  thanks again for the invitation to visit lsu .  shirley will fedex the receipts tomorrow .  vince  \" james r . garven \" on 02 / 08 / 2000 07 : 00 : 50 pm  to : vince j kaminski  cc :  subject : receipts from visit  dear vince ,  thanks again for taking the time to visit . ? both faculty and students got a  lot out of your presentations .  i have a favor to ask concerning the expense reimbursement process . ? can you  mail all travel and lodging receipts to my secretary joan payne at the  following address :  joan payne  department of finance  2163 ceba  louisiana state university  baton rouge , la ? 70803  thanks ,  jim garven  james r . garven  william h . wright , jr . endowed chair for financial services  department of finance  2158 ceba  e . j . ourso college of business administration  louisiana state university  baton rouge , la ? 70803 - 6308  voice ( 225 ) 388 - 0477 ? | ? fax : ( 800 ) 859 - 6361  e - mail : ? jgarven @ lsu . edu  home page : http : / / garven . lsu . edu  vita : http : / / garven . lsu . edu / dossier . html  research paper archive : http : / / garven . lsu . edu / research . html '"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('datasets/emails.csv')\n",
    "new_df = df.copy()\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cc6db61d-f95c-4939-82cf-f889742129f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5728 entries, 0 to 5727\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    5728 non-null   object\n",
      " 1   spam    5728 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 89.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ae6a09d6-3004-4a15-b883-6705f297af68",
   "metadata": {},
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a0e9f78d-daed-4289-8d6b-4808e567ed53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam\n",
       "0    4360\n",
       "1    1368\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['spam'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "74722d2f-31fb-4d63-98ce-80cbc71798fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\RSSpe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "\n",
    "class Parser():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.stemmer = nltk.PorterStemmer()\n",
    "        self.stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "        self.punctuation = list(string.punctuation)\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        for c in self.punctuation:\n",
    "            text = text.replace(c, \"\")\n",
    "        text = text.replace(\"\\t\", \" \")\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        tokens = list(filter(None, text.split(\" \")))\n",
    "        # Stemming of the tokens\n",
    "        return [self.stemmer.stem(w) for w in tokens if w not in self.stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "688d6a21-0830-4a92-a615-7339efb16927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       natur irresist corpor ident lt realli hard rec...\n",
       "1       stock trade gunsling fanni merril muzo colza a...\n",
       "2       unbeliev new home made easi im want show homeo...\n",
       "3       color print special request addit inform click...\n",
       "4       money get softwar cd softwar compat great grow...\n",
       "                              ...                        \n",
       "5723    research develop charg gpg forward shirley cre...\n",
       "5724    receipt visit jim thank invit visit lsu shirle...\n",
       "5725    enron case studi updat wow day super thank muc...\n",
       "5726    interest david pleas call shirley crenshaw ass...\n",
       "5727    news aurora updat aurora version fastest model...\n",
       "Length: 5728, dtype: object"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Descargar las stopwords de nltk si es necesario\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# Inicializar el stemmer y las stopwords\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_email(text):\n",
    "    # 1. Convertir a minúsculas\n",
    "    text = text['text'].lower()\n",
    "\n",
    "    # 2. Eliminar meta-datos del correo (Subject, To, Cc, etc.)\n",
    "    meta_data_patterns = [r'subject\\s*:', r'to\\s*:', r'cc\\s*:', r're\\s*:']\n",
    "    for pattern in meta_data_patterns:\n",
    "        text = re.sub(pattern, '', text, flags=re.IGNORECASE)\n",
    "\n",
    "    # 3. Eliminar direcciones de correo electrónico\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "\n",
    "    # 4. Eliminar URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "\n",
    "    # 5. Eliminar caracteres especiales y números\n",
    "    text = re.sub(r'\\d+', '', text)  # Eliminar números\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Eliminar puntuación\n",
    "\n",
    "    # 6. Tokenizar el texto (dividir en palabras)\n",
    "    tokens = text.split()\n",
    "\n",
    "    # 7. Eliminar stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # 8. Aplicar stemming (o lematización)\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "\n",
    "    # 9. Juntar los tokens de nuevo en un texto limpio\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "new_df.apply(clean_email, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a77c605-258f-4148-a4f1-3fee399cd77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_val_test_split(df, rstate=42, shuffle=True, stratify=None):\n",
    "    strat = df[stratify] if stratify else None\n",
    "    train_set, test_set = train_test_split(\n",
    "        df, test_size=0.4, random_state=rstate, shuffle=shuffle, stratify=strat)\n",
    "    strat = test_set[stratify] if stratify else None\n",
    "    val_set, test_set = train_test_split(\n",
    "        test_set, test_size=0.5, random_state=rstate, shuffle=shuffle, stratify=strat)\n",
    "    return (train_set, val_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "45bd8435-63a5-48e7-8ef0-eaebf5e00936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "receipt visit jim thank invit visit lsu shirley fedex receipt tomorrow vinc jame r garven pm vinc j kaminski receipt visit dear vinc thank take time visit faculti student got lot present favor ask concern expens reimburs process mail travel lodg receipt secretari joan payn follow address joan payn depart financ ceba louisiana state univers baton roug la thank jim garven jame r garven william h wright jr endow chair financi servic depart financ ceba e j ourso colleg busi administr louisiana state univers baton roug la voic fax e mail jgarven lsu edu home page http garven lsu edu vita http garven lsu edu dossier html research paper archiv http garven lsu edu research html\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Descargar las stopwords de nltk si es necesario\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# Inicializar el stemmer y las stopwords\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_email(text):\n",
    "    # 1. Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "\n",
    "    # 2. Eliminar meta-datos del correo (Subject, To, Cc, etc.)\n",
    "    meta_data_patterns = [r'subject\\s*:', r'to\\s*:', r'cc\\s*:', r're\\s*:']\n",
    "    for pattern in meta_data_patterns:\n",
    "        text = re.sub(pattern, '', text, flags=re.IGNORECASE)\n",
    "\n",
    "    # 3. Eliminar direcciones de correo electrónico\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "\n",
    "    # 4. Eliminar URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "\n",
    "    # 5. Eliminar caracteres especiales y números\n",
    "    text = re.sub(r'\\d+', '', text)  # Eliminar números\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Eliminar puntuación\n",
    "\n",
    "    # 6. Tokenizar el texto (dividir en palabras)\n",
    "    tokens = text.split()\n",
    "\n",
    "    # 7. Eliminar stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # 8. Aplicar stemming (o lematización)\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "\n",
    "    # 9. Juntar los tokens de nuevo en un texto limpio\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "# Ejemplo de correo\n",
    "email_text = '''\n",
    "Subject: re : receipts from visit  jim ,  thanks again for the invitation to visit lsu .  shirley will fedex the receipts tomorrow .  vince  \" james r . garven \" on 02 / 08 / 2000 07 : 00 : 50 pm  to : vince j kaminski  cc :  subject : receipts from visit  dear vince ,  thanks again for taking the time to visit . ? both faculty and students got a  lot out of your presentations .  i have a favor to ask concerning the expense reimbursement process . ? can you  mail all travel and lodging receipts to my secretary joan payne at the  following address :  joan payne  department of finance  2163 ceba  louisiana state university  baton rouge , la ? 70803  thanks ,  jim garven  james r . garven  william h . wright , jr . endowed chair for financial services  department of finance  2158 ceba  e . j . ourso college of business administration  louisiana state university  baton rouge , la ? 70803 - 6308  voice ( 225 ) 388 - 0477 ? | ? fax : ( 800 ) 859 - 6361  e - mail : ? jgarven @ lsu . edu  home page : http : / / garven . lsu . edu  vita : http : / / garven . lsu . edu / dossier . html  research paper archive : http : / / garven . lsu . edu / research . html\n",
    "'''\n",
    "\n",
    "# Limpiar el correo\n",
    "cleaned_email = clean_email(email_text)\n",
    "print(cleaned_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42690ab5-4974-4b4d-a393-e203fb2461f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
